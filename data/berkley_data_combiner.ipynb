{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of compress failed: Traceback (most recent call last):\n",
      "  File \"c:\\tmp\\rtvis22-cde\\.venv\\Lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 273, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"c:\\tmp\\rtvis22-cde\\.venv\\Lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 471, in superreload\n",
      "    module = reload(module)\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Vorto\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\importlib\\__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 621, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 936, in exec_module\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 1074, in get_code\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 1004, in source_to_code\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"c:\\tmp\\rtvis22-cde\\data\\compress.py\", line 2\n",
      "    %load_ext Cython\n",
      "    ^\n",
      "SyntaxError: invalid syntax\n",
      "]\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'Cython'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[102], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m get_ipython()\u001b[39m.\u001b[39mrun_line_magic(\u001b[39m'\u001b[39m\u001b[39mload_ext\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mautoreload\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m get_ipython()\u001b[39m.\u001b[39;49mrun_line_magic(\u001b[39m'\u001b[39;49m\u001b[39mload_ext\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mCython\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      4\u001b[0m get_ipython()\u001b[39m.\u001b[39mrun_line_magic(\u001b[39m'\u001b[39m\u001b[39mautoreload\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m2\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mimportlib\u001b[39;00m\n",
      "File \u001b[1;32mc:\\tmp\\rtvis22-cde\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:2414\u001b[0m, in \u001b[0;36mInteractiveShell.run_line_magic\u001b[1;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[0;32m   2412\u001b[0m     kwargs[\u001b[39m'\u001b[39m\u001b[39mlocal_ns\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_local_scope(stack_depth)\n\u001b[0;32m   2413\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuiltin_trap:\n\u001b[1;32m-> 2414\u001b[0m     result \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   2416\u001b[0m \u001b[39m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[0;32m   2417\u001b[0m \u001b[39m# when using magics with decodator @output_can_be_silenced\u001b[39;00m\n\u001b[0;32m   2418\u001b[0m \u001b[39m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[0;32m   2419\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(fn, magic\u001b[39m.\u001b[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[39mFalse\u001b[39;00m):\n",
      "File \u001b[1;32mc:\\tmp\\rtvis22-cde\\.venv\\Lib\\site-packages\\IPython\\core\\magics\\extension.py:33\u001b[0m, in \u001b[0;36mExtensionMagics.load_ext\u001b[1;34m(self, module_str)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m module_str:\n\u001b[0;32m     32\u001b[0m     \u001b[39mraise\u001b[39;00m UsageError(\u001b[39m'\u001b[39m\u001b[39mMissing module name.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> 33\u001b[0m res \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mshell\u001b[39m.\u001b[39;49mextension_manager\u001b[39m.\u001b[39;49mload_extension(module_str)\n\u001b[0;32m     35\u001b[0m \u001b[39mif\u001b[39;00m res \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39malready loaded\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m     36\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mThe \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m extension is already loaded. To reload it, use:\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m module_str)\n",
      "File \u001b[1;32mc:\\tmp\\rtvis22-cde\\.venv\\Lib\\site-packages\\IPython\\core\\extensions.py:76\u001b[0m, in \u001b[0;36mExtensionManager.load_extension\u001b[1;34m(self, module_str)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Load an IPython extension by its module name.\u001b[39;00m\n\u001b[0;32m     70\u001b[0m \n\u001b[0;32m     71\u001b[0m \u001b[39mReturns the string \"already loaded\" if the extension is already loaded,\u001b[39;00m\n\u001b[0;32m     72\u001b[0m \u001b[39m\"no load function\" if the module doesn't have a load_ipython_extension\u001b[39;00m\n\u001b[0;32m     73\u001b[0m \u001b[39mfunction, or None if it succeeded.\u001b[39;00m\n\u001b[0;32m     74\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     75\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 76\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_load_extension(module_str)\n\u001b[0;32m     77\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mModuleNotFoundError\u001b[39;00m:\n\u001b[0;32m     78\u001b[0m     \u001b[39mif\u001b[39;00m module_str \u001b[39min\u001b[39;00m BUILTINS_EXTS:\n",
      "File \u001b[1;32mc:\\tmp\\rtvis22-cde\\.venv\\Lib\\site-packages\\IPython\\core\\extensions.py:91\u001b[0m, in \u001b[0;36mExtensionManager._load_extension\u001b[1;34m(self, module_str)\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshell\u001b[39m.\u001b[39mbuiltin_trap:\n\u001b[0;32m     90\u001b[0m     \u001b[39mif\u001b[39;00m module_str \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m sys\u001b[39m.\u001b[39mmodules:\n\u001b[1;32m---> 91\u001b[0m         mod \u001b[39m=\u001b[39m import_module(module_str)\n\u001b[0;32m     92\u001b[0m     mod \u001b[39m=\u001b[39m sys\u001b[39m.\u001b[39mmodules[module_str]\n\u001b[0;32m     93\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_load_ipython_extension(mod):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\importlib\\__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    124\u001b[0m             \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m    125\u001b[0m         level \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m--> 126\u001b[0m \u001b[39mreturn\u001b[39;00m _bootstrap\u001b[39m.\u001b[39;49m_gcd_import(name[level:], package, level)\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1206\u001b[0m, in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1178\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1142\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'Cython'"
     ]
    }
   ],
   "source": [
    "\n",
    "%load_ext autoreload\n",
    "%load_ext Cython\n",
    "\n",
    "%autoreload 2\n",
    "\n",
    "import importlib\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "# Explicitely For Crawling\n",
    "import requests\n",
    "import sys\n",
    "from lxml import etree\n",
    "import asyncio\n",
    "import aiohttp  # pip install aiohttp\n",
    "import aiofiles  # pip install aiofiles\n",
    "\n",
    "import compress as comp\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "OUTPUT_FILE_PATH = \"sources\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetch Station Summaries\n",
    "Since there is no already zipped file of the station data @http://berkeleyearth.lbl.gov/auto/Stations/TAVG/Text/, I had to write a little crawler which downloads all of the files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If started you need to completely kill the kernel to get rid of the asynchronous download tasks\n",
    "LOCAL_FILE_PATH = \"sources/berkley_station_summaries/\"\n",
    "WEB_FILE_PATH = \"http://berkeleyearth.lbl.gov/auto/Stations/TAVG/Text/\"\n",
    "\n",
    "def getSiteDom(url):\n",
    "    resp = requests.get(url)\n",
    "    if resp.status_code != 200:\n",
    "        print(f\"Couldn't download url {url}\")\n",
    "        return None\n",
    "    return etree.HTML(resp.text)\n",
    "\n",
    "def downloadFile(url, lpath):\n",
    "    resp = requests.get(url)\n",
    "    if resp.status_code != 200:\n",
    "        print(f\"Couldn't download file {url}\")\n",
    "        return\n",
    "    open(lpath, \"wb\").write(resp.content)\n",
    "\n",
    "def downloadFilesParallel(urls, lpaths, maxp = 10):\n",
    "    sema = asyncio.BoundedSemaphore(maxp)\n",
    "    pbar = tqdm(total=len(urls), desc=\"Downloading files\")\n",
    "    async def fetch_file(url, lpath):\n",
    "        async with sema, aiohttp.ClientSession() as session:\n",
    "            async with session.get(url) as resp:\n",
    "                if resp.status != 200:\n",
    "                    print(f\" -> Couldn't download file {url}\")\n",
    "                    pbar.update(1)\n",
    "                    return\n",
    "                data = await resp.read()\n",
    "        async with aiofiles.open(lpath, \"wb\") as outfile:\n",
    "            await outfile.write(data)\n",
    "            pbar.update(1)\n",
    "\n",
    "    async def fetch_files(urls, lpaths):\n",
    "        tasks = [asyncio.ensure_future(fetch_file(url,lpath)) for url,lpath in zip(urls, lpaths)]\n",
    "        await asyncio.gather(*tasks)\n",
    "    \n",
    "    loop = asyncio.get_event_loop()\n",
    "    try:\n",
    "        loop.run_until_complete(fetch_files(urls, lpaths))\n",
    "    finally:\n",
    "        loop.run_until_complete(loop.shutdown_asyncgens())\n",
    "        loop.close()\n",
    "    pbar.close()\n",
    "\n",
    "def getAllFileNames(url):\n",
    "    dom = getSiteDom(url)\n",
    "    elements = dom.xpath(\"//td/a[contains(@href,'.txt')]\")\n",
    "    ret = []\n",
    "    for element in elements:\n",
    "        ret.append(element.get(\"href\"))\n",
    "    return ret\n",
    "\n",
    "filenames = getAllFileNames(WEB_FILE_PATH)\n",
    "#filenames = filenames[slice(20)]\n",
    "urls = [WEB_FILE_PATH + filename for filename in filenames]\n",
    "lpaths = [LOCAL_FILE_PATH + filename for filename in filenames]\n",
    "files = len(os.listdir(LOCAL_FILE_PATH))\n",
    "if (len(os.listdir(LOCAL_FILE_PATH)) >= len(urls)):\n",
    "    print(\"Aborted because more or the same amount of files exists in the download folder than there are to download.\")\n",
    "#downloadFilesParallel(urls, lpaths, maxp=20)\n",
    "#for filename in tqdm(filenames, desc=\"Downloading files\"):\n",
    "#    url = WEB_FILE_PATH + filename\n",
    "#    localFile = LOCAL_FILE_PATH + filename\n",
    "#    downloadFile(url, localFile)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Station Summaries\n",
    "Imports all files inside `data\\sources\\berkley_station_summaries`. Buffers it in a binary file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data imported from binary file!!!\n"
     ]
    }
   ],
   "source": [
    "LOCAL_FILE_PATH = \"sources/berkley_station_summaries\"\n",
    "OUTPUT_FILE_BINARY = \"sources/stationummaries.parquet.gzip\"\n",
    "\n",
    "NEW_PART_EVERY = 1000\n",
    "FORCE_RECREATION = False\n",
    "\n",
    "#name = 0.80N-8.84E\n",
    "def getDataForOnePosition(id):\n",
    "    file = f\"{LOCAL_FILE_PATH}/{id}-TAVG-Data.txt\"\n",
    "\n",
    "    # Extract Data from comment at begin of trend file:\n",
    "    chunk = \"\"\n",
    "    with open(file) as myFile:\n",
    "        chunk = myFile.read(4069)\n",
    "\n",
    "    #x = re.findall(r\"for the location:[\\s%]+([\\d.\\dNSEW ]+),([\\d.\\dNSEW ]+)\", chunk); #for location\n",
    "    lat = re.findall(r\"Latitude:\\s+([\\w\\S ]+) \\+\", chunk)\n",
    "    lat = lat[0] if len(lat) > 0 else \"\"\n",
    "    lon = re.findall(r\"Longitude:\\s+([\\w\\S ]+) \\+\", chunk)\n",
    "    lon = lon[0] if len(lon) > 0 else \"\"\n",
    "    if lat == \"\" or lon == \"\":\n",
    "        #print(f\"Couldn't  evaluate latitude and longitude for station {id}\")\n",
    "        return None\n",
    "\n",
    "    header = [\"Year\", \"Month\", \"Raw Data Temperature\", \"Raw Data Anomaly\", \"QC Failed\",   \"Continuity Breaks\", \"Adjusted Data Temperature\", \"Adjusted Data Anomaly\", \"Regional Temperature\", \"Regional Anomaly\"]\n",
    "    df = pd.read_csv(file, delimiter=\"\\s+\", header=None, comment=\"%\", names=header, usecols = [0,1,2,3,6,7,8,9], encoding='latin-1')\n",
    "\n",
    "    df[\"lat\"] = lat\n",
    "    df[\"lon\"] = lon\n",
    "    df[\"stationId\"] = id\n",
    "    return df\n",
    "\n",
    "\n",
    "def getIDsFromDirectory(dir):\n",
    "    ids = set()\n",
    "    for path in os.listdir(dir):\n",
    "        if not os.path.isfile(os.path.join(dir, path)):\n",
    "            continue\n",
    "        if not \"-TAVG-Data.txt\" in path:\n",
    "            continue\n",
    "        ids.add(path.replace(\"-TAVG-Data.txt\", \"\"))\n",
    "    return ids\n",
    "\n",
    "if os.path.isfile(OUTPUT_FILE_BINARY) and not FORCE_RECREATION:\n",
    "    df_merged = pd.read_parquet(OUTPUT_FILE_BINARY)\n",
    "    print(\"Data imported from binary file!!!\")\n",
    "else:\n",
    "    allIds = getIDsFromDirectory(LOCAL_FILE_PATH)\n",
    "    idCount = len(allIds)\n",
    "    partCount = math.ceil(idCount / NEW_PART_EVERY)\n",
    "    curPartId = 0\n",
    "    df_parts = [ pd.DataFrame({'A':[]}) for _ in range(partCount) ]\n",
    "    sumEntries = 0\n",
    "    pbar = tqdm(total=idCount, desc=\"Merging files\")\n",
    "    for ind, id in enumerate(allIds):\n",
    "        pbar.update(1)\n",
    "        pbar.set_description(f\"Merging files (Counts - Part:{len(df_parts[curPartId])}, Overall:{len(df_parts[curPartId]) + sumEntries}) [Part {curPartId + 1}/{partCount}]\")\n",
    "        #pbar.write(f\"Working on {positionName}...\")\n",
    "        df = getDataForOnePosition(id)\n",
    "        if not df is None and len(df) > 0:\n",
    "            #pbar.write(f\" -> Read {len(df)} entries\")\n",
    "            if len(df_parts[curPartId]) > 0:\n",
    "                df_parts[curPartId] = pd.concat([df_parts[curPartId], df], ignore_index=True)\n",
    "            else:\n",
    "                df_parts[curPartId] = df\n",
    "        \n",
    "        if ind > 0 and ind % NEW_PART_EVERY == 0:\n",
    "            sumEntries += len(df_parts[curPartId])\n",
    "            curPartId += 1\n",
    "    pbar.close()\n",
    "\n",
    "    df_merged = pd.DataFrame({'A':[]})\n",
    "    for pId in tqdm(range(partCount), desc=\"Merging dataframe parts\"):\n",
    "        if len(df_merged) > 0:\n",
    "            df_merged = pd.concat([df_merged, df_parts[pId]], ignore_index=True)\n",
    "        else:\n",
    "            df_merged = df_parts[pId]\n",
    "\n",
    "    df_parts = None\n",
    "    print(\"Saving to binary file...\")\n",
    "    df_merged.to_parquet(OUTPUT_FILE_BINARY, compression=\"gzip\")\n",
    "\n",
    "df_stations = df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = df_stations\n",
    "df.rename(columns={\"Adjusted Data Temperature\":\"AverageTemperature\", \"lat\":\"Latitude\", \"lon\":\"Longitude\"}, inplace=True)\n",
    "df = df[[\"Year\", \"Month\", \"AverageTemperature\", \"Latitude\", \"Longitude\"]]\n",
    "df = df.astype({\n",
    "        'Latitude': np.float32, \n",
    "        'Longitude': np.float32,\n",
    "        'Year': np.uint32,\n",
    "        'Month': np.uint32,\n",
    "        'AverageTemperature': np.float32,\n",
    "        'AverageTemperatureUncertainty': np.float32,\n",
    "        'Interpolated': bool\n",
    "        })\n",
    "df.dtypes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Output File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = df_stations\n",
    "df_data.rename(columns={\"Adjusted Data Temperature\":\"AverageTemperature\", \"lat\":\"Latitude\", \"lon\":\"Longitude\"}, inplace=True)\n",
    "df_data = df_data[[\"Year\", \"Month\", \"AverageTemperature\", \"Latitude\", \"Longitude\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping NaNs... -> removed 5312332 rows\n",
      "Converting data types...\n",
      "Creating location ID... -> Found 40596 distinct locations\n",
      "Merging rows with same year, month and locid... -> merged 141757 rows\n",
      "Creating CTILB ID... -> Found 498148 distinct continous temperature index blocks\n",
      "Get Header-Data...\n",
      "Create DM-Column...\n",
      "== HEADER ==\n",
      " -> Counts: Temperatures=15841847; Locations=40596; CTILBs=498148\n",
      " -> Datebounds:  {'db_first_year': 1701, 'db_last_year': 2013, 'db_first_month': 1, 'db_last_month': 10}\n",
      " -> Temperaturebounds:  {'db_min_temp': -72.312, 'db_max_temp': 42.108}\n",
      " -> Byte-Counts: bc_temperature=1, bc_temperatureindex=3, bc_monthdifference=2, bc_ctilbindex=3\n",
      "Discretize Temperature...\n",
      "Calculating discretization error...\n",
      "       Discretization error  Discretization error with Uncertainty\n",
      "count          1.584185e+07                           1.584185e+07\n",
      "mean           2.243828e-01                           2.243828e-01\n",
      "std            1.295455e-01                           1.295455e-01\n",
      "min            0.000000e+00                           0.000000e+00\n",
      "25%            1.121750e-01                           1.121750e-01\n",
      "50%            2.244034e-01                           2.244034e-01\n",
      "75%            3.365831e-01                           3.365831e-01\n",
      "max            4.487038e-01                           4.487038e-01\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>locid</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>AverageTemperature</th>\n",
       "      <th>AverageTemperatureUncertainty</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Interpolated</th>\n",
       "      <th>ctilbid</th>\n",
       "      <th>dm</th>\n",
       "      <th>disTemp</th>\n",
       "      <th>disError</th>\n",
       "      <th>disErrorUnc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5278</th>\n",
       "      <td>39</td>\n",
       "      <td>1982</td>\n",
       "      <td>8</td>\n",
       "      <td>-72.311996</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-78.455070</td>\n",
       "      <td>106.846252</td>\n",
       "      <td>False</td>\n",
       "      <td>315</td>\n",
       "      <td>3379</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5605</th>\n",
       "      <td>41</td>\n",
       "      <td>1958</td>\n",
       "      <td>8</td>\n",
       "      <td>-71.900002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-78.400002</td>\n",
       "      <td>87.599998</td>\n",
       "      <td>False</td>\n",
       "      <td>348</td>\n",
       "      <td>3091</td>\n",
       "      <td>0</td>\n",
       "      <td>0.411995</td>\n",
       "      <td>0.411995</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      locid  Year  Month  AverageTemperature  AverageTemperatureUncertainty   \n",
       "5278     39  1982      8          -72.311996                            0.0  \\\n",
       "5605     41  1958      8          -71.900002                            0.0   \n",
       "\n",
       "       Latitude   Longitude  Interpolated  ctilbid    dm  disTemp  disError   \n",
       "5278 -78.455070  106.846252         False      315  3379        0  0.000000  \\\n",
       "5605 -78.400002   87.599998         False      348  3091        0  0.411995   \n",
       "\n",
       "      disErrorUnc  \n",
       "5278     0.000000  \n",
       "5605     0.411995  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>locid</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>AverageTemperature</th>\n",
       "      <th>AverageTemperatureUncertainty</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Interpolated</th>\n",
       "      <th>ctilbid</th>\n",
       "      <th>dm</th>\n",
       "      <th>disTemp</th>\n",
       "      <th>disError</th>\n",
       "      <th>disErrorUnc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1957</td>\n",
       "      <td>1</td>\n",
       "      <td>-27.799999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-90.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>3072</td>\n",
       "      <td>99</td>\n",
       "      <td>0.090115</td>\n",
       "      <td>0.090115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1957</td>\n",
       "      <td>2</td>\n",
       "      <td>-38.217999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-90.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>3073</td>\n",
       "      <td>75</td>\n",
       "      <td>0.441055</td>\n",
       "      <td>0.441055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1957</td>\n",
       "      <td>3</td>\n",
       "      <td>-53.665001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-90.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>3074</td>\n",
       "      <td>41</td>\n",
       "      <td>0.250053</td>\n",
       "      <td>0.250053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1957</td>\n",
       "      <td>4</td>\n",
       "      <td>-56.368000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-90.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>3075</td>\n",
       "      <td>35</td>\n",
       "      <td>0.239292</td>\n",
       "      <td>0.239292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1957</td>\n",
       "      <td>5</td>\n",
       "      <td>-55.792000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-90.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>3076</td>\n",
       "      <td>36</td>\n",
       "      <td>0.366585</td>\n",
       "      <td>0.366585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15841842</th>\n",
       "      <td>40595</td>\n",
       "      <td>1958</td>\n",
       "      <td>6</td>\n",
       "      <td>-1.700000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>86.199997</td>\n",
       "      <td>-113.099998</td>\n",
       "      <td>False</td>\n",
       "      <td>498146</td>\n",
       "      <td>3089</td>\n",
       "      <td>157</td>\n",
       "      <td>0.165173</td>\n",
       "      <td>0.165173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15841843</th>\n",
       "      <td>40595</td>\n",
       "      <td>1958</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>86.199997</td>\n",
       "      <td>-113.099998</td>\n",
       "      <td>False</td>\n",
       "      <td>498147</td>\n",
       "      <td>3091</td>\n",
       "      <td>161</td>\n",
       "      <td>0.070351</td>\n",
       "      <td>0.070351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15841844</th>\n",
       "      <td>40595</td>\n",
       "      <td>1958</td>\n",
       "      <td>9</td>\n",
       "      <td>-11.100000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>86.199997</td>\n",
       "      <td>-113.099998</td>\n",
       "      <td>False</td>\n",
       "      <td>498147</td>\n",
       "      <td>3092</td>\n",
       "      <td>136</td>\n",
       "      <td>0.187994</td>\n",
       "      <td>0.187994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15841845</th>\n",
       "      <td>40595</td>\n",
       "      <td>1958</td>\n",
       "      <td>10</td>\n",
       "      <td>-22.200001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>86.199997</td>\n",
       "      <td>-113.099998</td>\n",
       "      <td>False</td>\n",
       "      <td>498147</td>\n",
       "      <td>3093</td>\n",
       "      <td>111</td>\n",
       "      <td>0.305645</td>\n",
       "      <td>0.305645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15841846</th>\n",
       "      <td>40595</td>\n",
       "      <td>1958</td>\n",
       "      <td>11</td>\n",
       "      <td>-25.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>86.199997</td>\n",
       "      <td>-113.099998</td>\n",
       "      <td>False</td>\n",
       "      <td>498147</td>\n",
       "      <td>3094</td>\n",
       "      <td>105</td>\n",
       "      <td>0.197880</td>\n",
       "      <td>0.197880</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15841847 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          locid  Year  Month  AverageTemperature   \n",
       "0             0  1957      1          -27.799999  \\\n",
       "1             0  1957      2          -38.217999   \n",
       "2             0  1957      3          -53.665001   \n",
       "3             0  1957      4          -56.368000   \n",
       "4             0  1957      5          -55.792000   \n",
       "...         ...   ...    ...                 ...   \n",
       "15841842  40595  1958      6           -1.700000   \n",
       "15841843  40595  1958      8            0.000000   \n",
       "15841844  40595  1958      9          -11.100000   \n",
       "15841845  40595  1958     10          -22.200001   \n",
       "15841846  40595  1958     11          -25.000000   \n",
       "\n",
       "          AverageTemperatureUncertainty   Latitude   Longitude  Interpolated   \n",
       "0                                   0.0 -90.000000    0.000000         False  \\\n",
       "1                                   0.0 -90.000000    0.000000         False   \n",
       "2                                   0.0 -90.000000    0.000000         False   \n",
       "3                                   0.0 -90.000000    0.000000         False   \n",
       "4                                   0.0 -90.000000    0.000000         False   \n",
       "...                                 ...        ...         ...           ...   \n",
       "15841842                            0.0  86.199997 -113.099998         False   \n",
       "15841843                            0.0  86.199997 -113.099998         False   \n",
       "15841844                            0.0  86.199997 -113.099998         False   \n",
       "15841845                            0.0  86.199997 -113.099998         False   \n",
       "15841846                            0.0  86.199997 -113.099998         False   \n",
       "\n",
       "          ctilbid    dm  disTemp  disError  disErrorUnc  \n",
       "0               0  3072       99  0.090115     0.090115  \n",
       "1               0  3073       75  0.441055     0.441055  \n",
       "2               0  3074       41  0.250053     0.250053  \n",
       "3               0  3075       35  0.239292     0.239292  \n",
       "4               0  3076       36  0.366585     0.366585  \n",
       "...           ...   ...      ...       ...          ...  \n",
       "15841842   498146  3089      157  0.165173     0.165173  \n",
       "15841843   498147  3091      161  0.070351     0.070351  \n",
       "15841844   498147  3092      136  0.187994     0.187994  \n",
       "15841845   498147  3093      111  0.305645     0.305645  \n",
       "15841846   498147  3094      105  0.197880     0.197880  \n",
       "\n",
       "[15841847 rows x 13 columns]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importlib.reload(comp)\n",
    "comp.compress_dataset(df_data, output_path=OUTPUT_FILE_PATH, discretizeresolution=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Import Local Summaries\n",
    "Imports all %position%-TAVG-Counts and %position%-TAVG-Trend Text-Files in a certain path and combines all the data in one dataframe. This dataframe is then being saved as a binary file. (Since the process takes quite some time and the dataset is huge)\n",
    "The data can be downloaded here: http://berkeleyearth.lbl.gov/auto/Local/TAVG/Text/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOCAL_FILE_PATH = \"sources/berkley_local_summaries\"\n",
    "OUTPUT_FILE_BINARY = \"sources/localsummaries.parquet.gzip\"\n",
    "FORCE_RECREATION = False\n",
    "\n",
    "#name = 0.80N-8.84E\n",
    "def getDataForOnePosition(name):\n",
    "    count_file = f\"{LOCAL_FILE_PATH}/{name}-TAVG-Counts.txt\"\n",
    "    trends_file = f\"{LOCAL_FILE_PATH}/{name}-TAVG-Trend.txt\"\n",
    "\n",
    "    # Extract Data from comment at begin of trend file:\n",
    "    chunk = \"\"\n",
    "    with open(trends_file) as myFile:\n",
    "        chunk = myFile.read(4069)\n",
    "\n",
    "    #x = re.findall(r\"for the location:[\\s%]+([\\d.\\dNSEW ]+),([\\d.\\dNSEW ]+)\", chunk); #for location\n",
    "    country = re.findall(r\"Country: ([\\w\\S ]+)\", chunk) #for Country\n",
    "    country = country[0] if len(country) > 0 else \"\"\n",
    "    citys = re.findall(r\"Nearby Cities: ([\\w\\S ]+)\", chunk)\n",
    "    citys = citys[0] if len(citys) > 0 else \"\"\n",
    "    temperatureList = re.findall(r\"Jan[\\s]+Feb[\\s]+Mar[\\s]+Apr[\\s]+May[\\s]+Jun[\\s]+Jul[\\s]+Aug[\\s]+Sep[\\s]+Oct[\\s]+Nov[\\s]+Dec\\s+%%([\\w\\s\\S]+)%%\", chunk)[0].strip().split(\" \")\n",
    "    temperatureList = list(filter(None, temperatureList))\n",
    "    temperatureList = [eval(i) for i in temperatureList]\n",
    "\n",
    "    latlon = name.split(\"-\")\n",
    "\n",
    "    assert(len(temperatureList) == 12)\n",
    "    #df_tempMonthList = pd.DataFrame.from_dict(temperatureList)\n",
    "\n",
    "    header = [\"Year\", \"Month\", \"\", \"Within 10 km\", \"Within 50 km\", \"Within 100 km\", \"Within 250 km\", \"Within 500 km\", \"Within 1000 km\"]\n",
    "    df_counts = pd.read_csv(count_file, delimiter=\"\\s+\", header=None, comment=\"%\", names=header, usecols = [0,1,3,4,5,6,7,8], encoding='latin-1')\n",
    "    header = [\"Year\", \"Month\",  \"Monthly Anomaly\", \"Monthly Unc.\", \"Annual Anomaly\", \"Annual Unc.\",   \"Five-year Anomaly\", \"Five-year Unc.\", \"Ten-year Anomaly\", \"Ten-year Unc.\",  \"Twenty-year Anomaly\", \"Twenty-year Unc.\"]\n",
    "    df_trends = pd.read_csv(trends_file, delimiter=\"\\s+\", header=None, comment=\"%\", names=header, usecols = [0,1,2,3], encoding='latin-1')\n",
    "    \n",
    "    # Drop Records based on the distance of the record stations\n",
    "    #df_counts = df_counts[df_counts[\"Within 500 km\"] > 0]\n",
    "    if len(df_counts) == 0:\n",
    "        return None\n",
    "\n",
    "    df_joined = pd.merge(df_counts, df_trends, how='left', left_on=['Year', 'Month'], right_on=['Year', 'Month'])\n",
    "    df_joined['AverageTemperature'] = df_joined.apply(lambda x: x['Monthly Anomaly'] + temperatureList[x['Month'].astype(int) - 1], axis=1)\n",
    "    df_joined[\"Latitude\"] = latlon[0]\n",
    "    df_joined[\"Longitude\"] = latlon[1]\n",
    "    df_joined[\"Country\"] = country\n",
    "    df_joined[\"City\"] = citys\n",
    "    df_joined[\"dt\"] = df_joined.apply(lambda x: str(x['Year']) + \"-\" + '{0:0>2}'.format(x['Month']) + \"-01\", axis=1)\n",
    "    df_joined.rename(columns={\"Monthly Unc.\": \"AverageTemperatureUncertainty\"}, inplace=True)\n",
    "\n",
    "    #df_joined = df_joined[[\"dt\", \"AverageTemperature\", \"AverageTemperatureUncertainty\", \"City\", \"Country\", \"Latitude\", \"Longitude\"]]\n",
    "    #df_joined = df_joined[[\"dt\", \"AverageTemperature\", \"AverageTemperatureUncertainty\", \"Latitude\", \"Longitude\"]]\n",
    "    return df_joined\n",
    "\n",
    "\n",
    "def getPositionsFromDirectory(dir):\n",
    "    positions = set()\n",
    "    for path in os.listdir(dir):\n",
    "        if not os.path.isfile(os.path.join(dir, path)):\n",
    "            continue\n",
    "        if not \"-TAVG-Trend.txt\" in path:\n",
    "            continue\n",
    "        positions.add(path.replace(\"-TAVG-Trend.txt\", \"\"))\n",
    "    return positions\n",
    "\n",
    "if os.path.isfile(OUTPUT_FILE_BINARY) and not FORCE_RECREATION:\n",
    "    df_merged = pd.read_parquet(OUTPUT_FILE_BINARY)\n",
    "    print(\"Data imported from binary file!!!\")\n",
    "else:\n",
    "    allPositions = getPositionsFromDirectory(LOCAL_FILE_PATH)\n",
    "    print(f\"{len(allPositions)} different Location-Files will be combined\")\n",
    "    df_merged = pd.DataFrame({'A' : []})\n",
    "    pbar = tqdm(total=len(allPositions), desc=\"Merging files\")\n",
    "    for ind, positionName in enumerate(allPositions):\n",
    "        pbar.update(1)\n",
    "        pbar.set_description(f\"Merging files ({len(df_merged)} temp entries)\")\n",
    "        #pbar.write(f\"Working on {positionName}...\")\n",
    "        df = getDataForOnePosition(positionName)\n",
    "        if df is None:\n",
    "            continue\n",
    "        if len(df) < 0:\n",
    "            #pbar.write(f\" -> Returned empty dataframe\")\n",
    "            continue\n",
    "        #pbar.write(f\" -> Read {len(df)} entries\")\n",
    "        if len(df_merged) > 0:\n",
    "            df_merged = pd.concat([df_merged, df], ignore_index=True)\n",
    "        else:\n",
    "            df_merged = df\n",
    "    pbar.close()\n",
    "    df_merged.to_parquet(OUTPUT_FILE_BINARY, compression=\"gzip\")\n",
    "\n",
    "df_local = df_merged\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OUTPUT FOR INTERPOLATION\n",
    "The following code outputs the data such that we can further process it with `interpolate_data.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OUTPUT FOR INTERPOLATION\n",
    "OUTPUT_FILE = \"C:/Users/gkimmersdorfer/Documents/rtvis22-cde/data/sources/GlobalLandTemperaturesByCity.csv\"\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "df_output = df_local\n",
    "df_output['City'] = \"\"\n",
    "df_output['Country'] = \"\"\n",
    "df_output['src'] = 0\n",
    "pd.options.mode.chained_assignment = 'warn'\n",
    "df_output = df_output[[\"dt\", \"AverageTemperature\", \"AverageTemperatureUncertainty\", \"City\", \"Country\", \"Latitude\", \"Longitude\"]]\n",
    "df_output.to_csv(OUTPUT_FILE, index=False, sep=\",\", encoding=\"utf-8\", header=True)\n",
    "print(f\"Output-File created successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OUTPUT WITH DELETED NANS WITHOUT INTERPOLATION READY FOR COMPRESS\n",
    "OUTPUT_FILE = \"C:/Users/gkimmersdorfer/Documents/rtvis22-cde/data/sources/GlobalLandTemperaturesByCity_interpolated.csv\"\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "df_output = df_local.dropna()\n",
    "print(f\"Dropped {len(df_local) - len(df_output)} NaN-entries.\")\n",
    "df_output['City'] = \"\"\n",
    "df_output['Country'] = \"\"\n",
    "df_output['src'] = 0\n",
    "pd.options.mode.chained_assignment = 'warn'\n",
    "\n",
    "df_output = df_output[[\"dt\", \"AverageTemperature\", \"AverageTemperatureUncertainty\", \"City\", \"Country\", \"Latitude\", \"Longitude\", \"src\"]]\n",
    "df_output.to_csv(OUTPUT_FILE, index=False, sep=\",\", encoding=\"utf-8\", header=True)\n",
    "print(f\"Output-File created successfully\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cde_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
